{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14205592,"sourceType":"datasetVersion","datasetId":9060344}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==========================================\n# 1. INSTALLATION & IMPORTS\n# ==========================================\n!pip install openai-whisper\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport whisper\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    TrainingArguments, \n    Trainer,\n    EarlyStoppingCallback\n)\n\n# Configuration\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nMODEL_NAME = \"roberta-base\"  # Excellent for syntax and semantic understanding\nTRAIN_CSV = \"/kaggle/input/shlhiring/dataset/csvs/train.csv\"\nTEST_CSV = \"/kaggle/input/shlhiring/dataset/csvs/test.csv\"\nTRAIN_AUDIO_DIR = \"/kaggle/input/shlhiring/dataset/audios/train/\"\nTEST_AUDIO_DIR = \"/kaggle/input/shlhiring/dataset/audios/test/\"\n\n# ==========================================\n# 2. PREPROCESSING: SPEECH-TO-TEXT (WHISPER)\n# ==========================================\n# We use Whisper to convert spoken audio into text.\nstt_model = whisper.load_model(\"base\").to(DEVICE)\n\ndef transcribe_data(df, audio_dir):\n    \"\"\"Transcribes audio files listed in a dataframe.\"\"\"\n    transcriptions = []\n    for filename in tqdm(df['filename'], desc=f\"Transcribing {audio_dir}\"):\n        # Append extension if missing\n        file_path = os.path.join(audio_dir, filename if filename.endswith('.wav') else f\"{filename}.wav\")\n        \n        if not os.path.exists(file_path):\n            transcriptions.append(\"\")\n            continue\n            \n        try:\n            # Transcribe audio\n            result = stt_model.transcribe(file_path)\n            transcriptions.append(result['text'].strip())\n        except Exception as e:\n            print(f\"Error on {filename}: {e}\")\n            transcriptions.append(\"\")\n            \n    df['text'] = transcriptions\n    return df[df['text'] != \"\"].reset_index(drop=True)\n\nprint(\"--- Step 1: Transcription ---\")\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)\n\ntrain_df = transcribe_data(train_df, TRAIN_AUDIO_DIR)\ntest_df = transcribe_data(test_df, TEST_AUDIO_DIR)\n\n# ==========================================\n# 3. DATASET PREPARATION\n# ==========================================\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize_fn(texts):\n    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=256)\n\nclass GrammarDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels is not None:\n            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n        return item\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\n# Split data for local validation\nX_train, X_val, y_train, y_val = train_test_split(\n    train_df['text'].tolist(), \n    train_df['label'].tolist(), \n    test_size=0.15, \n    random_state=42\n)\n\ntrain_set = GrammarDataset(tokenize_fn(X_train), y_train)\nval_set = GrammarDataset(tokenize_fn(X_val), y_val)\n\n# ==========================================\n# 4. MODEL TRAINING (REGRESSION)\n# ==========================================\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    rmse = np.sqrt(mean_squared_error(labels, logits))\n    return {\"rmse\": rmse}\n\n# Load model with 1 output label for regression\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1).to(DEVICE)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./grammar_engine_results\",\n    num_train_epochs=10,\n    per_device_train_batch_size=8,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"rmse\",\n    greater_is_better=False,\n    logging_steps=10,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_set,\n    eval_dataset=val_set,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n)\n\nprint(\"\\n--- Step 2: Training Regression Model ---\")\ntrainer.train()\n\n# ==========================================\n# 5. FINAL EVALUATION (COMPULSORY RMSE)\n# ==========================================\n# Predict on the full training set\nfull_train_dataset = GrammarDataset(tokenize_fn(train_df['text'].tolist()))\ntrain_preds = trainer.predict(full_train_dataset)\nfinal_train_rmse = np.sqrt(mean_squared_error(train_df['label'], train_preds.predictions))\n\nprint(\"\\n\" + \"=\"*30)\nprint(f\"FINAL TRAINING RMSE: {final_train_rmse:.4f}\")\nprint(\"=\"*30)\n\n# ==========================================\n# 6. INFERENCE & SUBMISSION\n# ==========================================\nprint(\"\\n--- Step 3: Generating Submission ---\")\ntest_set = GrammarDataset(tokenize_fn(test_df['text'].tolist()))\ntest_preds = trainer.predict(test_set)\n\n# Ensure scores are within valid 0-5 range\ntest_df['label'] = np.clip(test_preds.predictions.flatten(), 0.0, 5.0)\n\n# Save only the required columns\ntest_df[['filename', 'label']].to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T08:55:05.469221Z","iopub.execute_input":"2025-12-18T08:55:05.469568Z","iopub.status.idle":"2025-12-18T09:11:32.838815Z","shell.execute_reply.started":"2025-12-18T08:55:05.469529Z","shell.execute_reply":"2025-12-18T09:11:32.838044Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\nRequirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.11.12)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n--- Step 1: Transcription ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Transcribing /kaggle/input/shlhiring/dataset/audios/train/:   0%|          | 0/409 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11adc502d9bf4d03a53ffcff92f607d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Transcribing /kaggle/input/shlhiring/dataset/audios/test/:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dc626c950cc4fe3bcb49f4710b6117e"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n--- Step 2: Training Regression Model ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='154' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [154/220 01:28 < 00:38, 1.71 it/s, Epoch 7/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rmse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.946400</td>\n      <td>0.545499</td>\n      <td>0.738579</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.584200</td>\n      <td>0.719834</td>\n      <td>0.848430</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.515200</td>\n      <td>0.333711</td>\n      <td>0.577677</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.395900</td>\n      <td>0.471399</td>\n      <td>0.686585</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.229400</td>\n      <td>0.225359</td>\n      <td>0.474719</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.170600</td>\n      <td>0.278351</td>\n      <td>0.527590</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.139700</td>\n      <td>0.225598</td>\n      <td>0.474971</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\n==============================\nFINAL TRAINING RMSE: 0.4584\n==============================\n\n--- Step 3: Generating Submission ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"submission.csv created successfully.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}